# data-imputations-datasets
This repository is used to release the public datasets for data imputation tasks. These datasets are supported via the project from Vietnam National University Ho Chi Minh City with the project ID -  DS.2023.18.01

The datasets, including those we collected ourselves and other public datasets, used in our experiments can be categorized as follows

## 1. Stock market dataset
We collected data on historical stock transactions on 3 large markets in Vietnam, namely HNX, HOSE, and UPCOM. The data comprised of 1731 stocks, was collected from 04/012016 to 31/12/2021.

Please cite our journal paper when using this dataset for further purposes.
```
@inbook{an2023portfolio,
author = {Phan-Thi, Thuy-An and Dinh, Nu and Thanh, Son and Nguyen, Binh},
year = {2023},
month = {09},
pages = {},
title = {Portfolio Optimization for Long-Term Investment: An Empirical Study},
isbn = {9781643684307},
doi = {10.3233/FAIA230238}
}
```

## 2. Air pollution datasets
### 2.1. Collected data in Dalat and Hanoi
We collected data on air quality in Dalat and Hanoi (Cau Giay District and Minh Khai District). data from these locations constitute 3 datasets: [Dalat](https://github.com/BinhMisfit/air-pollution-datasets/tree/main/Dalat-air-quality-dataset), [Cau Giay](https://github.com/BinhMisfit/air-pollution-datasets/blob/main/Hanoi-air-quality-dataset/Hanoi_Cau_Giay.csv), [Minh Khai](https://github.com/BinhMisfit/air-pollution-datasets/blob/main/Hanoi-air-quality-dataset/Hanoi_Minh_Khai.csv).

Please cite our journal papers when using our datasets for further purposes.
```
@inproceedings{ton2023air,
  title={Air Pollution Forecasting Using Multimodal Data},
  author={Ton-Thien, Minh-Anh and Nguyen, Chuong Thi and Le, Quang M and Duong, Dat Q and Dao, Minh-Son and Nguyen, Binh T},
  booktitle={International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems},
  pages={360--371},
  year={2023},
  organization={Springer}
}
```
```
@inproceedings{dao2023overview,
  title={Overview of MediaEval 2022 Urban Air: Urban Life and Air Pollution},
  author={Dao, Minh-Son and Dang, Thanh-Hai and Nguyen-Tai, Tan-Loc and Nguyen, Thanh-Binh and Dang-Nguyen, Duc-Tien},
  booktitle={Proc. of the MediaEval 2022 Workshop},
  pages={13--15},
  year={2023}
}
```
### 2.2. Frankfurt dataset
Please refer to [https://www.kaggle.com/datasets/avibagul80/air-quality-dataset](https://www.kaggle.com/datasets/avibagul80/air-quality-dataset)

### 2.3. Taiwan dataset
Please refer to [https://www.kaggle.com/datasets/nelsonchu/air-quality-in-northern-taiwan](https://www.kaggle.com/datasets/nelsonchu/air-quality-in-northern-taiwan)

### 2.4. Beijing dataset
Please refer to [https://archive.ics.uci.edu/dataset/501/beijing+multi+site+air+quality+data](https://archive.ics.uci.edu/dataset/501/beijing+multi+site+air+quality+data)

## 3. Multi-model datasets
### 3.1. IMDB
Please refer to [https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews)
### 3.2. Fashion MNIST
Please refer to [https://github.com/zalandoresearch/fashion-mnist](https://github.com/zalandoresearch/fashion-mnist)
### 3.3. MNIST
Please refer to [http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)
### 3.4. Cifar10
Please refer to [https://www.cs.toronto.edu/~kriz/cifar.html](https://www.cs.toronto.edu/~kriz/cifar.html)

## 4. Imbalanced datasets
### 4.1. Ecoli
Please refer to the dataset "ecoli" from the [imbalanced.datasets](https://imbalanced-learn.org/stable/datasets/index.html) package
### 4.2. US Crime
Please refer to the dataset "us_crime" from the [imbalanced.datasets](https://imbalanced-learn.org/stable/datasets/index.html) package
### 4.3. Ozone Level
Please refer to the dataset "ozone_level" from the [imbalanced.datasets](https://imbalanced-learn.org/stable/datasets/index.html) package
### 4.4. Page Blocks
Please refer to [https://archive.ics.uci.edu/dataset/78/page+blocks+classification](https://archive.ics.uci.edu/dataset/78/page+blocks+classification)
### 4.5. Statlog Landsat
Please refer to [https://archive.ics.uci.edu/dataset/146/statlog+landsat+satellite](https://archive.ics.uci.edu/dataset/146/statlog+landsat+satellite)

## 5. Other datasets
### 5.1. Thyroid
Please refer to [https://archive.ics.uci.edu/dataset/102/thyroid+disease](https://archive.ics.uci.edu/dataset/102/thyroid+disease)
### 5.2. Yeast
Please refer to [https://archive.ics.uci.edu/dataset/110/yeast](https://archive.ics.uci.edu/dataset/110/yeast)
### 5.3. Seeds
Please refer to [https://archive.ics.uci.edu/dataset/236/seeds](https://archive.ics.uci.edu/dataset/236/seeds)
### 5.4. Iris
Please refer to [https://archive.ics.uci.edu/dataset/53/iris](https://archive.ics.uci.edu/dataset/53/iris)
### 5.5. Wine
Please refer to [https://archive.ics.uci.edu/dataset/109/wine](https://archive.ics.uci.edu/dataset/109/wine)
### 5.6. Breast Cancer
Please refer to [https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic](https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic)
### 5.7. Gene
Please refer to [https://archive.ics.uci.edu/dataset/401/gene+expression+cancer+rna+seq](https://archive.ics.uci.edu/dataset/401/gene+expression+cancer+rna+seq)
### 5.8. Parkinson
Please refer to [https://archive.ics.uci.edu/dataset/470/parkinson+s+disease+classification](https://archive.ics.uci.edu/dataset/470/parkinson+s+disease+classification)
### 5.9. Digits
Please refer to [https://archive.ics.uci.edu/dataset/80/optical+recognition+of+handwritten+digits](https://archive.ics.uci.edu/dataset/80/optical+recognition+of+handwritten+digits)
### 5.10. Ionosphere
Please refer to [https://archive.ics.uci.edu/dataset/52/ionosphere](https://archive.ics.uci.edu/dataset/52/ionosphere)
### 5.11. Bank Marketing
Please refer to [https://archive.ics.uci.edu/dataset/222/bank+marketing](https://archive.ics.uci.edu/dataset/222/bank+marketing)
### 5.12. Heart Disease
Please refer to [https://archive.ics.uci.edu/dataset/45/heart+disease](https://archive.ics.uci.edu/dataset/45/heart+disease)
### 5.13. Statlog
Please refer to [https://archive.ics.uci.edu/dataset/144/statlog+german+credit+data](https://archive.ics.uci.edu/dataset/144/statlog+german+credit+data)
### 5.14. Student Performance
Please refer to [https://archive.ics.uci.edu/dataset/320/student+performance](https://archive.ics.uci.edu/dataset/320/student+performance)

# Details of our experiments
Please refer to our papers for more details of our experiments for data imputation tasks.
```
@article{10.1371/journal.pone.0306303,
    doi = {10.1371/journal.pone.0306303},
    author = {Hua, Van AND Nguyen, Thu AND Dao, Minh-Son AND Nguyen, Hien D. AND Nguyen, Binh T.},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {The impact of data imputation on air quality prediction problem},
    year = {2024},
    month = {09},
    volume = {19},
    url = {https://doi.org/10.1371/journal.pone.0306303},
    pages = {1-39},
    abstract = {With rising environmental concerns, accurate air quality predictions have become paramount as they help in planning preventive measures and policies for potential health hazards and environmental problems caused by poor air quality. Most of the time, air quality data are time series data. However, due to various reasons, we often encounter missing values in datasets collected during data preparation and aggregation steps. The inability to analyze and handle missing data will significantly hinder the data analysis process. To address this issue, this paper offers an extensive review of air quality prediction and missing data imputation techniques for time series, particularly in relation to environmental challenges. In addition, we empirically assess eight imputation methods, including mean, median, kNNI, MICE, SAITS, BRITS, MRNN, and Transformer, to scrutinize their impact on air quality data. The evaluation is conducted using diverse air quality datasets gathered from numerous cities globally. Based on these evaluations, we offer practical recommendations for practitioners dealing with missing data in time series scenarios for environmental data.},
    number = {9},
}
```
```
@article{LE2025100720,
  title = {Multimodal missing data in healthcare: A comprehensive review and future directions},
  journal = {Computer Science Review},
  volume = {56},
  pages = {100720},
  year = {2025},
  issn = {1574-0137},
  doi = {https://doi.org/10.1016/j.cosrev.2024.100720},
  url = {https://www.sciencedirect.com/science/article/pii/S1574013724001035},
  author = {Lien P. Le and Thu Nguyen and Michael A. Riegler and Pål Halvorsen and Binh T. Nguyen},
  keywords = {Missing data, Healthcare, Diagnosis, Multimodal data, Fusion method},
  abstract = {The rapid advancement in healthcare data collection technologies and the importance of using multimodal data for accurate diagnosis leads to a surge in multimodal data characterized by different types, structures, and missing values. Machine learning algorithms for predicting or analyzing usually demand the completeness of data. As a result, handling missing data has become a critical concern in the healthcare sector. This survey paper comprehensively reviews recent works on handling multimodal missing data in healthcare. We emphasize methods for synthesizing data from various modalities or multiple sources in imputing missing data, including early fusion, late fusion, and intermediate fusion methods for missing data imputation. The main objective of this study is to identify gaps in the surveyed area and list future tasks and challenges in handling multimodal missing data in healthcare. This review is valuable for researchers and practitioners in healthcare data analysis. It provides insights into using fusion methods to improve data quality and healthcare outcomes.}
}
```
```
@article{10596282,
  author={Vo, Tuan L. and Do, Quan Huu and Nguyen, Thu and Halvorsen, Pål and Riegler, Michael A. and Nguyen, Binh T.},
  journal={IEEE Access}, 
  title={The Effects of Data Imputation on Covariance and Inverse Covariance Matrix Estimation}, 
  year={2024},
  volume={12},
  number={},
  pages={134688-134701},
  keywords={Covariance matrices;Imputation;Estimation;Accuracy;Parameter estimation;Correlation;Bayes methods;Maximum likelihood detection;Missing data;maximum likelihood estimate;parameter estimation},
  doi={10.1109/ACCESS.2024.3427404}}
```
```
@InProceedings{10.1007/978-3-031-36819-6_3,
  author="Nguyen, Thuong H. T.
  and Le, Bao
  and Nguyen, Phuc
  and Tran, Linh G. H.
  and Nguyen, Thu
  and Nguyen, Binh T.",
  editor="Fujita, Hamido
  and Wang, Yinglin
  and Xiao, Yanghua
  and Moonis, Ali",
  title="Principal Components Analysis Based Imputation for Logistic Regression",
  booktitle="Advances and Trends in Artificial Intelligence. Theory and Applications",
  year="2023",
  publisher="Springer Nature Switzerland",
  address="Cham",
  pages="28--36",
  abstract="The field of AI and machine learning is constantly evolving, and as the size of data continues to grow, so does the need for accurate and efficient methods of data processing. However, the data is not always perfect, and missing data is becoming common and occurs more frequently. Therefore, imputation techniques, aside from precision, needed to be scalable. For that reason, we examine the performance of Principle Components Analysis Imputation (PCAI) [9], an imputation speeding up framework, for logistic regression. Note that the coefficients of a logistic regression model are usually used for interpretation. Therefore, in addition to examining the improvement in the speed of PCAI, we examine how the coefficients of fitted logistic regression models change when using this imputation speeding-up mechanism. To demonstrate the efficiency of the mentioned method, the model's performance is compared against frequently used imputation methods on three popular datasets: Fashion MNIST, Gene, and Parkinson. And achieves lower time and better accuracy in most experiments.",
  isbn="978-3-031-36819-6"
}
```
```
@article{NGUYEN2022108082,
  title = {DPER: Direct Parameter Estimation for Randomly missing data},
  journal = {Knowledge-Based Systems},
  volume = {240},
  pages = {108082},
  year = {2022},
  issn = {0950-7051},
  doi = {https://doi.org/10.1016/j.knosys.2021.108082},
  url = {https://www.sciencedirect.com/science/article/pii/S0950705121011540},
  author = {Thu Nguyen and Khoi Minh Nguyen-Duy and Duy Ho Minh Nguyen and Binh T. Nguyen and Bruce Alan Wade},
  keywords = {Randomly missing data, Parameter estimation, MLEs},
  abstract = {Parameter estimation is an important problem with applications in discriminant analysis, hypothesis testing, etc. Yet, when there are missing values in the data sets, commonly used imputation-based techniques are usually needed before further parameter estimation since works in direct parameter estimation exists in only limited settings. Unfortunately, such two-step procedures (imputation-parameter estimation) can be computationally expensive. Therefore, it motivates us to propose novel algorithms that directly find the maximum likelihood estimates (MLEs) for an arbitrary one-class/multiple-class randomly missing data set under some mild assumptions. Furthermore, due to the direct computation, our algorithms do not require multiple iterations through the data, thus promising to be less time-consuming while maintaining superior estimation performance than state-of-the-art methods under comparisons. We validate these claims by empirical results on various data sets of different sizes.}
}
```
```
@article{ThuNguyen_2021:EPEM:efficient_parameter_estimation_for_multiple_class,
  title = {EPEM: Efficient Parameter Estimation for Multiple Class Monotone Missing Data},
  journal = {Information Sciences},
  volume = {567},
  pages = {1-22},
  year = {2021},
  issn = {0020-0255},
  doi = {https://doi.org/10.1016/j.ins.2021.02.077},
  url = {https://www.sciencedirect.com/science/article/pii/S0020025521002346},
  author = {Thu Nguyen and Duy H.M. Nguyen and Huy Nguyen and Binh T. Nguyen and Bruce A. Wade},
  keywords = {Missing data, Monotone, Parameter estimation},
  abstract = {The problem of monotone missing data has been broadly studied during the last two decades and has many applications in various fields such as bioinformatics or statistics. Commonly used imputation techniques require multiple iterations through the data before yielding convergence. Moreover, those approaches may introduce extra noises and biases to the subsequent modeling. In this work, we derive exact formulas and propose a novel algorithm to compute the maximum likelihood estimators (MLEs) of a multiple class, monotone missing dataset when all the covariance matrices of all categories are assumed to be equal, namely Efficient Parameter Estimation for Multiple Class Monotone Missing Data (EPEM). We then illustrate an application of our proposed methods in Linear Discriminant Analysis (LDA). As the computation is exact, our EPEM algorithm does not require multiple iterations through the data as other imputation approaches, thus promising to handle much less time-consuming than other methods. This effectiveness was validated by empirical results when EPEM reduced the error rates significantly and required a short computation time compared to several imputation-based approaches. We also release all codes and data of our experiments in a GitHub repository to contribute to the research community related to this problem.}
}
```
```
@InProceedings{PhucNguyen_2023:faster_imputation,
  author="Nguyen, Phuc
  and Tran, Linh G. H.
  and Le, Bao H.
  and Nguyen, Thuong H. T.
  and Nguyen, Thu
  and Nguyen, Hien D.
  and Nguyen, Binh T.",
  editor="Nguyen, Ngoc Thanh
  and Boonsang, Siridech
  and Fujita, Hamido
  and Hnatkowska, Bogumi{\l}a
  and Hong, Tzung-Pei
  and Pasupa, Kitsuchart
  and Selamat, Ali",
  title="Faster Imputation Using Singular Value Decomposition for Sparse Data",
  booktitle="Intelligent Information and Database Systems",
  year="2023",
  publisher="Springer Nature Singapore",
  address="Singapore",
  pages="135--146",
  abstract="With the emergence of many knowledge-based systems worldwide, there have been more and more applications using different kinds of data and solving significant daily problems. Among that, the issues of missing data in such systems have become more popular, especially in data-driven areas. Other research on the imputation problem has dealt with partial and missing data. This study aims to investigate the imputation techniques for sparse data using the Singular Value Decomposition technique, namely SVDI. We explore the application of the SVDI framework for image classification and text classification tasks that involve sparse data. The experimental results show that the proposed SVDI method improves the speed and accuracy of the imputation process when compared to the PCAI method. We aim to publish our codes related to the SVDI later for the relevant research community.",
  isbn="978-981-99-5834-4"
}
```
```
@article{nguyen4260235PMF,
  title={PMF: Efficient Parameter Estimation for Data Sets with Missing Data in Some Features},
  author={Nguyen, Thu and Phan, Nhan Thanh and Hoang, Ha Van and Halvorsen, P{\aa}l and Riegler, Michael A and Nguyen, Binh T},
  journal={Available at SSRN 4260235}
}
```





